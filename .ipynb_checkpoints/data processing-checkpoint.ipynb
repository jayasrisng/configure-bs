{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118f7b7b-eed0-4038-99e8-b8b5559864de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from xror import XROR  # Ensure xror module is available in the notebook environment\n",
    "from dask.diagnostics import ProgressBar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "import dask.dataframe as dd\n",
    "\n",
    "logging.basicConfig(filename= 'xror_parsing_errors.log', level=logging.INFO, format= '%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0216fb-f9ac-431a-b9d7-3cbe13a73e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_files_exist(root_folders):\n",
    "    for root_folder in root_folders:\n",
    "        csv_files = glob.glob(os.path.join(root_folder, '**/*.csv'), recursive=True)\n",
    "        if not csv_files:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c27d17-b99e-4354-b903-bdb87e4d974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files already exist. Skipping XROR processing.\n"
     ]
    }
   ],
   "source": [
    "def process_xror_files(root_folder_path):\n",
    "    xror_files = glob.glob(os.path.join(root_folder_path, '**/*.xror'), recursive=True)\n",
    "    for file_path in xror_files:\n",
    "        try:\n",
    "            base_name = os.path.splitext(file_path)[0]\n",
    "            csv_file_path = base_name + '.csv'\n",
    "            if os.path.exists(csv_file_path):\n",
    "                logging.info(f\"CSV file already exists for {file_path}. Skipping.\")\n",
    "                continue\n",
    "            with open(file_path, 'rb') as f:\n",
    "                binary_data = f.read()\n",
    "            xror_data = XROR.unpack(binary_data)\n",
    "            if len(xror_data.data['frames'][0]) != len(frame_columns):\n",
    "                logging.warning(f\"Column mismatch in {file_path}. Expected {len(frame_columns)} columns, found {len(xror_data.data['frames'][0])}.\")\n",
    "                continue\n",
    "            df_frames = pd.DataFrame(xror_data.data['frames'], columns=frame_columns)\n",
    "            df_frames['directionOK'] = df_frames.apply(lambda row: row['saberDirX'] > 0 and row['saberDirY'] > 0, axis=1)\n",
    "            df_frames.to_csv(csv_file_path, index=False)\n",
    "            logging.info(f\"DataFrame saved to CSV successfully for file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "root_folders = ['chunk1', 'chunk2', 'chunk3']\n",
    "if not csv_files_exist(root_folders):\n",
    "    for root_folder in root_folders:\n",
    "        process_xror_files(root_folder)\n",
    "else:\n",
    "    print(\"CSV files already exist. Skipping XROR processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a219e8d-39a9-43dc-a4aa-c4cbdc9d882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_done(root_folders):\n",
    "    for root_folder in root_folders:\n",
    "        normalized_files = glob.glob(os.path.join(root_folder, '**/*_normalized.csv'), recursive=True)\n",
    "        if not normalized_files:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d0f2a-75c8-4f11-b036-0abc868f5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_csv_files(root_folders):\n",
    "    for root_folder in root_folders:\n",
    "        csv_files = glob.glob(os.path.join(root_folder, '**/*.csv'), recursive=True)\n",
    "        csv_files = [f for f in csv_files if '_normalized.csv' not in f]\n",
    "        for file_path in csv_files:\n",
    "            try:\n",
    "                normalized_file_path = file_path.replace('.csv', '_normalized.csv')\n",
    "                if os.path.exists(normalized_file_path):\n",
    "                    continue\n",
    "                data = pd.read_csv(file_path)\n",
    "                scaler = StandardScaler()\n",
    "                numeric_cols = data.select_dtypes(include=['float64', 'int']).columns\n",
    "                data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "                data.to_csv(normalized_file_path, index=False)\n",
    "                print(f\"Data normalized and saved successfully for file: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error normalizing file {file_path}: {e}\")\n",
    "\n",
    "if not normalization_done(root_folders):\n",
    "    normalize_csv_files(root_folders)\n",
    "else:\n",
    "    print(\"CSV files are already normalized. Skipping normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04a190-9c84-40c8-8074-34766f79d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import os\n",
    "\n",
    "def create_skill_feature_mapping(root_folders, output_file='user_skill_feature_mapping.csv'):\n",
    "    # Create the file pattern for all normalized CSVs\n",
    "    file_patterns = [os.path.join(root, '**/*_normalized.csv') for root in root_folders]\n",
    "    # Load the files into a Dask DataFrame\n",
    "    ddf = dd.read_csv(file_patterns, include_path_column=True)\n",
    "\n",
    "    # Extract user_id and chunk_id from the file paths\n",
    "    ddf['user_id'] = ddf['path'].str.extract(r'/([^/]+)/[^/]+\\.csv$')[0]\n",
    "    ddf['chunk_id'] = ddf['path'].str.extract(r'/(chunk\\d+)/')[0]\n",
    "\n",
    "    # Drop the path column as it's no longer needed\n",
    "    ddf = ddf.drop('path', axis=1)\n",
    "\n",
    "    # Define the aggregations needed for skill assessment\n",
    "    aggregations = {\n",
    "        'cutDirDeviation': ['mean', 'std', 'min', 'max'],\n",
    "        'cutDistanceToCenter': ['mean', 'std', 'min', 'max'],\n",
    "        'wasCutTooSoon': ['mean', 'std'],  # Binary columns typically use mean to represent the fraction of 'True'\n",
    "        'beforeCutRating': ['mean', 'std', 'min', 'max'],\n",
    "        'afterCutRating': ['mean', 'std', 'min', 'max'],\n",
    "        'saberSpeed': ['mean', 'std', 'min', 'max'],\n",
    "        'cutAngle': ['mean', 'std', 'min', 'max']\n",
    "    }\n",
    "\n",
    "    # Perform the aggregation\n",
    "    grouped_ddf = ddf.groupby(['chunk_id', 'user_id']).agg(aggregations)\n",
    "\n",
    "    # Flatten column headers\n",
    "    grouped_ddf.columns = ['_'.join(col).strip() for col in grouped_ddf.columns.values]\n",
    "\n",
    "    # Reset the index to make chunk_id and user_id into columns\n",
    "    grouped_ddf = grouped_ddf.reset_index()\n",
    "\n",
    "    # Use ProgressBar to monitor progress\n",
    "    with ProgressBar():\n",
    "        # Save to CSV as a single file\n",
    "        grouped_ddf.to_csv(output_file, index=False, single_file=True)\n",
    "        print(f\"Skill feature mapping saved to {output_file}\")\n",
    "\n",
    "# Define root folders and output file name\n",
    "root_folders = ['chunk1', 'chunk2', 'chunk3']\n",
    "output_file = 'user_skill_feature_mapping.csv'\n",
    "\n",
    "# Recreate the skill feature mapping if it doesn't exist\n",
    "if not os.path.exists(output_file):\n",
    "    create_skill_feature_mapping(root_folders, output_file=output_file)\n",
    "else:\n",
    "    print(\"Skill feature mapping already exists. Skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ad281-e14f-4475-af0a-ca45dc73ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'user_skill_feature_mapping.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def rank_metric(series, higher_is_better=True):\n",
    "    if higher_is_better:\n",
    "        return series.rank(method='average', ascending=False)\n",
    "    else:\n",
    "        return series.rank(method='average', ascending=True)\n",
    "\n",
    "# Rank users based on the features\n",
    "df['cutDirDeviation_rank'] = rank_metric(df['cutDirDeviation_mean'], higher_is_better=False) \n",
    "df['cutDistanceToCenter_rank'] = rank_metric(df['cutDistanceToCenter_mean'], higher_is_better=False) \n",
    "df['wasCutTooSoon_rank'] = rank_metric(df['wasCutTooSoon_mean'], higher_is_better=False)  \n",
    "df['ratingImprovement_rank'] = rank_metric(df['afterCutRating_mean'] - df['beforeCutRating_mean'], higher_is_better=True)\n",
    "df['saberSpeed_rank'] = rank_metric(df['saberSpeed_mean'], higher_is_better=True) \n",
    "df['cutAngle_rank'] = rank_metric(df['cutAngle_mean'], higher_is_better=True)\n",
    "\n",
    "# Combine the ranks into a final score with weighted averages\n",
    "df['finalRankScore'] = (\n",
    "    df['cutDirDeviation_rank'] * 0.3 +  # Precision\n",
    "    df['cutDistanceToCenter_rank'] * 0.3 +  # Precision\n",
    "    df['wasCutTooSoon_rank'] * 0.1 +  # Timing\n",
    "    df['ratingImprovement_rank'] * 0.2 +  # Improvement\n",
    "    df['saberSpeed_rank'] * 0.05 +  # Speed\n",
    "    df['cutAngle_rank'] * 0.05  # Consistency\n",
    ")\n",
    "\n",
    "# Make sure to scale the final rank score to a 1-10 range\n",
    "df['scaledRankScore'] = 1 + 9 * (df['finalRankScore'] - df['finalRankScore'].min()) / (df['finalRankScore'].max() - df['finalRankScore'].min())\n",
    "\n",
    "# Now round the scaled rank scores to the nearest whole number\n",
    "df['scaledRankScore'] = df['scaledRankScore'].round().astype(int)\n",
    "\n",
    "print(df[['user_id', 'chunk_id', 'scaledRankScore']].head())\n",
    "\n",
    "output_file = 'user_skill_ratings_ranked_rounded.csv'\n",
    "df[['user_id', 'chunk_id', 'scaledRankScore']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Skill ratings saved with whole numbers to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ecead-ae2d-40c4-8ec3-33137aff73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of the final scaled scores\n",
    "plt.hist(df['scaledRankScore'], bins=10, edgecolor='black')\n",
    "plt.title('Distribution of Scaled Skill Scores (Real Data)')\n",
    "plt.xlabel('Skill Score (1-10)')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a5cd4-171c-40aa-a62d-3cd2123eccd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "root_path = '/srv/fs/my-notebooks'\n",
    "file_path = os.path.join(root_path, 'user_skill_feature_mapping.csv')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if there are any missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Check if the data is normalized (mean around 0 and std around 1 for key features)\n",
    "features_to_check = ['cutDirDeviation_mean', 'cutDirDeviation_std', \n",
    "                     'cutDistanceToCenter_mean', 'cutDistanceToCenter_std', \n",
    "                     'saberSpeed_mean', 'saberSpeed_std', 'cutAngle_mean', 'cutAngle_std']\n",
    "\n",
    "normalization_check = df[features_to_check].describe()\n",
    "\n",
    "# Check for extreme outliers (3 standard deviations from mean)\n",
    "outlier_check = np.abs(df[features_to_check]) > (3 * df[features_to_check].std())\n",
    "\n",
    "# Output the results\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "print(\"\\nFeature normalization check:\\n\", normalization_check)\n",
    "print(\"\\nOutliers check (True indicates potential outliers):\\n\", outlier_check.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05e045-86b6-4443-ae1e-e6a0e005ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import os\n",
    "\n",
    "def create_user_feature_mapping(root_folders, output_file='3fmapping.csv'):\n",
    "    # Create the file pattern for all normalized CSVs\n",
    "    file_patterns = [os.path.join(root, '**/*_normalized.csv') for root in root_folders]\n",
    "    # Load the files into a Dask DataFrame\n",
    "    ddf = dd.read_csv(file_patterns, include_path_column=True)\n",
    "    # Extract user_id and chunk_id from the file paths\n",
    "    ddf['user_id'] = ddf['path'].str.extract(r'/([^/]+)/[^/]+\\.csv$')[0]\n",
    "    ddf['chunk_id'] = ddf['path'].str.extract(r'/(chunk\\d+)/')[0]\n",
    "    # Drop the path column as it's no longer needed\n",
    "    ddf = ddf.drop('path', axis=1)\n",
    "    # Define the aggregations needed\n",
    "    aggregations = {\n",
    "        'saberDirX': ['mean', 'std', 'min', 'max'],\n",
    "        'saberDirY': ['mean', 'std', 'min', 'max'],\n",
    "        'saberDirZ': ['mean', 'std', 'min', 'max']\n",
    "    }\n",
    "    # Perform the aggregation\n",
    "    grouped_ddf = ddf.groupby(['chunk_id', 'user_id']).agg(aggregations)\n",
    "    # Flatten column headers\n",
    "    grouped_ddf.columns = ['_'.join(col).strip() for col in grouped_ddf.columns.values]\n",
    "    # Reset the index to make chunk_id and user_id into columns\n",
    "    grouped_ddf = grouped_ddf.reset_index()\n",
    "    # Use ProgressBar to monitor progress\n",
    "    with ProgressBar():\n",
    "        # Save to CSV as a single file\n",
    "        grouped_ddf.to_csv(output_file, index=False, single_file=True)\n",
    "        print(f\"User feature mapping saved to {output_file}\")\n",
    "\n",
    "# Recreate the user feature mapping if it doesn't exist\n",
    "root_folders = ['chunk1', 'chunk2', 'chunk3']\n",
    "if not os.path.exists('3fmapping.csv'):\n",
    "    create_user_feature_mapping(root_folders, output_file='3fmapping.csv')\n",
    "else:\n",
    "    print(\"User feature mapping already exists. Skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7404e9e-40fb-4df9-91f9-54138f04e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the user feature mapping (if not already loaded)\n",
    "user_feature_mapping = pd.read_csv('3fmapping.csv')\n",
    "total_users = user_feature_mapping['user_id'].nunique()\n",
    "\n",
    "# Define the target values to search for\n",
    "target_values = {\n",
    "    'saberDirX_mean': 4.651922525425667e-16,\n",
    "    'saberDirX_std': 1.000004920037097,\n",
    "    'saberDirX_min': -10.972303575118843,\n",
    "    'saberDirX_max': 4.239176532534343,\n",
    "    'saberDirY_mean': -8.608827695891577e-16,\n",
    "    'saberDirY_std': 1.000004920037097,\n",
    "    'saberDirY_min': -4.25651985215614,\n",
    "    'saberDirY_max': 4.254893132314185,\n",
    "    'saberDirZ_mean': -5.172523237994175e-17,\n",
    "    'saberDirZ_std': 1.000004920037097,\n",
    "    'saberDirZ_min': -6.4776688945541645,\n",
    "    'saberDirZ_max': 10.027852991443758\n",
    "}\n",
    "\n",
    "# Search for the user ID with the target values\n",
    "mask = (user_feature_mapping[list(target_values.keys())].apply(lambda row: row.round(8)) == pd.Series(target_values).round(8)).all(axis=1)\n",
    "matching_user = user_feature_mapping[mask]\n",
    "\n",
    "if not matching_user.empty:\n",
    "    print(\"Matching user found:\")\n",
    "    print(matching_user[['user_id', 'chunk_id']])\n",
    "else:\n",
    "    print(\"No matching user found.\")\n",
    "    \n",
    "print(f\"Total number of users in the dataset: {total_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79b90c-e23f-4e2d-b148-56534a813380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the user feature mapping\n",
    "user_feature_mapping = pd.read_csv('3fmapping.csv')\n",
    "total_users = user_feature_mapping['user_id'].nunique()\n",
    "\n",
    "# Select a random user (as before)\n",
    "random_user = user_feature_mapping.sample(n=1)\n",
    "\n",
    "# Extract features for the random user\n",
    "features = [\n",
    "    'saberDirX_mean', 'saberDirX_std', 'saberDirX_min', 'saberDirX_max',\n",
    "    'saberDirY_mean', 'saberDirY_std', 'saberDirY_min', 'saberDirY_max',\n",
    "    'saberDirZ_mean', 'saberDirZ_std', 'saberDirZ_min', 'saberDirZ_max'\n",
    "]\n",
    "\n",
    "target_values = random_user[features]\n",
    "\n",
    "# Set a threshold for closeness\n",
    "threshold = 1e-4\n",
    "\n",
    "# Compare values within the threshold for floating-point columns\n",
    "float_columns = user_feature_mapping[features].select_dtypes(include=['float']).columns\n",
    "mask_float = np.abs(user_feature_mapping[float_columns] - target_values[float_columns].values).le(threshold).all(axis=1)\n",
    "\n",
    "# For non-float columns (if any), compare them directly\n",
    "non_float_columns = user_feature_mapping[features].select_dtypes(exclude=['float']).columns\n",
    "mask_non_float = (user_feature_mapping[non_float_columns] == target_values[non_float_columns].values).all(axis=1)\n",
    "\n",
    "# Combine the two masks\n",
    "mask = mask_float & mask_non_float\n",
    "\n",
    "# Find the matching user\n",
    "matching_user = user_feature_mapping[mask]\n",
    "\n",
    "if not matching_user.empty:\n",
    "    print(\"Matching user found:\")\n",
    "    print(matching_user[['user_id', 'chunk_id']])\n",
    "else:\n",
    "    print(\"No matching user found.\")\n",
    "    \n",
    "print(f\"Total number of users in the dataset: {total_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e0a97-7d2d-4b1f-970e-738f94ee8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = user_feature_mapping[float_columns] - target_values[float_columns].values\n",
    "print(differences.abs().max())  # Print the maximum difference per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c049bc6-21b6-40a8-acaa-d162dde0295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example: Assuming you have 100 users\n",
    "real_users = np.arange(1, 101)  # Users from 1 to 100\n",
    "test_users = real_users.copy()  # Test users are exactly the same\n",
    "\n",
    "# Plotting the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(real_users, test_users, color='green', label='Test User Identified')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Real Users')\n",
    "plt.ylabel('Test Users (Identified)')\n",
    "plt.title('User Identification Accuracy (100%) Before Adding Synthetic Data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3ee1a-d2ce-4201-8f04-778e99ad578b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load real and synthetic data\n",
    "real_data_path = '/srv/fs/my-notebooks/user_skill_feature_mapping.csv'\n",
    "synthetic_data_path = '/srv/fs/my-notebooks/synthetic_user_data.csv'\n",
    "\n",
    "real_data = pd.read_csv(real_data_path)\n",
    "synthetic_data = pd.read_csv(synthetic_data_path)\n",
    "\n",
    "# Print the first few rows to verify the data\n",
    "print(real_data.head())\n",
    "print(synthetic_data.head())\n",
    "\n",
    "# Summary statistics of real and synthetic data\n",
    "real_stats = real_data.describe()\n",
    "synthetic_stats = synthetic_data.describe()\n",
    "\n",
    "print(\"Real Data Statistics:\\n\", real_stats)\n",
    "print(\"\\nSynthetic Data Statistics:\\n\", synthetic_stats)\n",
    "\n",
    "print(real_data.columns)\n",
    "print(synthetic_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b364c-24ad-4d2b-be79-b788fdcffb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "aggregated_features = ['cutDirDeviation_mean', 'cutDirDeviation_std', \n",
    "                       'cutDistanceToCenter_mean', 'cutDistanceToCenter_std', \n",
    "                       'saberSpeed_mean', 'saberSpeed_std', \n",
    "                       'cutAngle_mean', 'cutAngle_std']\n",
    "\n",
    "# Perform the KS test for each feature\n",
    "for feature in aggregated_features:\n",
    "    ks_stat, p_value = stats.ks_2samp(real_data[feature], synthetic_data[feature])\n",
    "    print(f\"KS Test for {feature}: Stat = {ks_stat}, P-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf461cdd-e5cd-4cef-8d50-539e61d92234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load real and synthetic data\n",
    "real_data_path = '/srv/fs/my-notebooks/user_skill_feature_mapping.csv'\n",
    "synthetic_data_path = '/srv/fs/my-notebooks/synthetic_user_data.csv'\n",
    "\n",
    "real_data = pd.read_csv(real_data_path)\n",
    "synthetic_data = pd.read_csv(synthetic_data_path)\n",
    "\n",
    "synthetic_df = pd.read_csv('/srv/fs/my-notebooks/synthetic_user_data.csv')\n",
    "aggregated_features = ['cutDirDeviation_mean', 'cutDirDeviation_std', \n",
    "                       'cutDistanceToCenter_mean', 'cutDistanceToCenter_std', \n",
    "                       'saberSpeed_mean', 'saberSpeed_std', \n",
    "                       'cutAngle_mean', 'cutAngle_std']\n",
    "\n",
    "# Example: Compare distributions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for feature in aggregated_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(real_data[feature], color='blue', label='Real Data', kde=True, bins=50)  # Reduce bins to 50\n",
    "    sns.histplot(synthetic_df[feature], color='orange', label='Synthetic Data', kde=True, bins=50)  # Reduce bins to 50\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce9b71-9860-454d-9dba-1f874c2168b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_data.isnull().sum())  # Check for missing values in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3623f80-0caa-4010-a4fc-bff1b86a9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load real and synthetic data\n",
    "real_data = pd.read_csv('/srv/fs/my-notebooks/user_skill_feature_mapping.csv')\n",
    "synthetic_data = pd.read_csv('/srv/fs/my-notebooks/synthetic_user_data.csv')\n",
    "\n",
    "# Select common features for comparison\n",
    "common_features = ['cutDirDeviation_mean', 'cutDirDeviation_std',\n",
    "                   'cutDistanceToCenter_mean', 'cutDistanceToCenter_std',\n",
    "                   'saberSpeed_mean', 'saberSpeed_std', 'cutAngle_mean', 'cutAngle_std']\n",
    "\n",
    "# Extract feature matrices\n",
    "X_real = real_data[common_features]\n",
    "X_synthetic = synthetic_data[common_features]\n",
    "\n",
    "# Generate synthetic user IDs for plotting\n",
    "synthetic_data['user_id'] = ['synthetic_user_' + str(i) for i in range(len(synthetic_data))]\n",
    "\n",
    "# Compute similarity between real and synthetic data using cosine similarity\n",
    "similarity_matrix = cosine_similarity(X_real, X_synthetic)\n",
    "\n",
    "# Identify best matches for each real user (based on highest similarity)\n",
    "best_matches = np.argmax(similarity_matrix, axis=1)\n",
    "\n",
    "# Check if the best match is the same synthetic user\n",
    "correct_matches = np.arange(len(X_real)) == best_matches\n",
    "\n",
    "# Calculate accuracy (percentage of correct identifications)\n",
    "accuracy = np.mean(correct_matches) * 100\n",
    "\n",
    "# Plot real users vs. test users identification\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(X_real)), correct_matches, marker='o', linestyle='-', color='b', label='Correct Matches')\n",
    "plt.xlabel('Real Users')\n",
    "plt.ylabel('Identification (1 = Correct, 0 = Incorrect)')\n",
    "plt.title(f'User Identification Accuracy: {accuracy:.2f}%')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy on synthetic data: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1665c-29cb-4f53-84b7-74c569a7211f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Load real and synthetic data\n",
    "real_data_path = '/srv/fs/my-notebooks/user_skill_feature_mapping.csv'\n",
    "synthetic_data_path = '/srv/fs/my-notebooks/synthetic_user_data.csv'\n",
    "\n",
    "real_data = pd.read_csv(real_data_path)\n",
    "synthetic_data = pd.read_csv(synthetic_data_path)\n",
    "\n",
    "# Define critical features to compare\n",
    "features = ['cutDirDeviation_mean', 'cutDirDeviation_std', \n",
    "            'cutDistanceToCenter_mean', 'cutDistanceToCenter_std', \n",
    "            'saberSpeed_mean', 'saberSpeed_std', \n",
    "            'cutAngle_mean', 'cutAngle_std']\n",
    "\n",
    "# Plot and compare distributions\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    sns.kdeplot(real_data[feature], color='blue', label='Real Data', shade=True)\n",
    "    sns.kdeplot(synthetic_data[feature], color='orange', label='Synthetic Data', shade=True)\n",
    "    \n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Kolmogorov-Smirnov Test\n",
    "    ks_stat, p_value = stats.ks_2samp(real_data[feature], synthetic_data[feature])\n",
    "    print(f\"K-S Test for {feature}:\")\n",
    "    print(f\"Statistic = {ks_stat:.4f}, p-value = {p_value:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Warning: {feature} has significantly different distributions in real vs synthetic data (p < 0.05)\\n\")\n",
    "    else:\n",
    "        print(f\"Pass: {feature} has similar distributions (p >= 0.05)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b21ceb-f355-4f67-821e-d7aa907f2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "real_data_path = '/srv/fs/my-notebooks/user_skill_feature_mapping.csv'\n",
    "synthetic_data_path = '/srv/fs/my-notebooks/synthetic_user_data.csv'\n",
    "\n",
    "real_data = pd.read_csv(real_data_path)\n",
    "synthetic_data = pd.read_csv(synthetic_data_path)\n",
    "\n",
    "# Define the features to plot\n",
    "features = ['cutDirDeviation_mean', 'saberSpeed_mean']\n",
    "\n",
    "# Plot and save KDE plots for the features\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.kdeplot(real_data[feature], color='blue', label='Real Data', fill=True)\n",
    "    sns.kdeplot(synthetic_data[feature], color='orange', label='Synthetic Data', fill=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'kde_{feature}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46ad9c-3e46-47ad-81d6-b3a2e4b495b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the synthetic data\n",
    "synthetic_file_path = 'synthetic_user_data.csv'\n",
    "synthetic_df = pd.read_csv(synthetic_file_path)\n",
    "\n",
    "def rank_metric(series, higher_is_better=True):\n",
    "    if higher_is_better:\n",
    "        return series.rank(method='average', ascending=False)\n",
    "    else:\n",
    "        return series.rank(method='average', ascending=True)\n",
    "\n",
    "# Rank users based on the features available in the synthetic data\n",
    "synthetic_df['cutDirDeviation_rank'] = rank_metric(synthetic_df['cutDirDeviation_mean'], higher_is_better=False) \n",
    "synthetic_df['cutDistanceToCenter_rank'] = rank_metric(synthetic_df['cutDistanceToCenter_mean'], higher_is_better=False) \n",
    "synthetic_df['saberSpeed_rank'] = rank_metric(synthetic_df['saberSpeed_mean'], higher_is_better=True) \n",
    "synthetic_df['cutAngle_rank'] = rank_metric(synthetic_df['cutAngle_mean'], higher_is_better=True)\n",
    "\n",
    "# Combine the ranks into a final score with weighted averages (without 'wasCutTooSoon_mean')\n",
    "synthetic_df['finalRankScore'] = (\n",
    "    synthetic_df['cutDirDeviation_rank'] * 0.3 +  # Precision\n",
    "    synthetic_df['cutDistanceToCenter_rank'] * 0.3 +  # Precision\n",
    "    synthetic_df['saberSpeed_rank'] * 0.2 +  # Speed\n",
    "    synthetic_df['cutAngle_rank'] * 0.2  # Consistency\n",
    ")\n",
    "\n",
    "# Make sure to scale the final rank score to a 1-10 range\n",
    "synthetic_df['scaledRankScore'] = 1 + 9 * (synthetic_df['finalRankScore'] - synthetic_df['finalRankScore'].min()) / (synthetic_df['finalRankScore'].max() - synthetic_df['finalRankScore'].min())\n",
    "\n",
    "# Now round the scaled rank scores to the nearest whole number\n",
    "synthetic_df['scaledRankScore'] = synthetic_df['scaledRankScore'].round().astype(int)\n",
    "\n",
    "# Display a preview of the ranked synthetic data\n",
    "print(synthetic_df[['cutDirDeviation_mean', 'scaledRankScore']].head())\n",
    "\n",
    "# Save the skill ratings for synthetic data\n",
    "synthetic_output_file = 'synthetic_user_skill_ratings_ranked_rounded.csv'\n",
    "synthetic_df[['cutDirDeviation_mean', 'scaledRankScore']].to_csv(synthetic_output_file, index=False)\n",
    "\n",
    "print(f\"Synthetic skill ratings saved with whole numbers to {synthetic_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffdb0af-c032-4ec7-9bf5-fea686f30551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distribution of scaled skill scores for synthetic data\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(synthetic_df['scaledRankScore'], bins=10, edgecolor='black', color='orange')\n",
    "plt.title('Distribution of Scaled Skill Scores (Synthetic Data)')\n",
    "plt.xlabel('Skill Score (1-10)')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82bb38d-b0d8-47e1-8c61-4df3023c9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e85087-a7ea-4324-96f5-b1827e2ac006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_env)",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
