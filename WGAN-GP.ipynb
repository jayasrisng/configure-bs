{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62070288-143d-45b3-814c-25108048cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 22:49:19.412333: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 22:49:19.412394: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 22:49:19.412449: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 22:49:19.435846: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 22:49:20.898223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
      "TensorFlow Version: 2.14.0\n",
      "Number of GPUs detected: 8\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')\n",
      "GPU: PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')\n",
      "CUDA Version: 11.8\n",
      "cuDNN Version: 8\n",
      "Pandas Version: 2.2.2\n",
      "NumPy Version: 1.26.4\n",
      "TensorFlow Privacy is installed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# Check if TensorFlow can access the GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Number of GPUs detected: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU: {gpu}\")\n",
    "else:\n",
    "    print(\"No GPU detected. TensorFlow is using the CPU.\")\n",
    "\n",
    "# Check CUDA and cuDNN versions\n",
    "cuda_version = tf.sysconfig.get_build_info().get(\"cuda_version\", \"Not found\")\n",
    "cudnn_version = tf.sysconfig.get_build_info().get(\"cudnn_version\", \"Not found\")\n",
    "print(f\"CUDA Version: {cuda_version}\")\n",
    "print(f\"cuDNN Version: {cudnn_version}\")\n",
    "\n",
    "# Check if Pandas is installed and its version\n",
    "try:\n",
    "    print(f\"Pandas Version: {pd.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Pandas is not installed.\")\n",
    "\n",
    "# Check if NumPy is installed and its version\n",
    "try:\n",
    "    print(f\"NumPy Version: {np.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"NumPy is not installed.\")\n",
    "\n",
    "# Check TensorFlow Privacy \n",
    "try:\n",
    "    from tensorflow_privacy import DPKerasAdamOptimizer\n",
    "    print(\"TensorFlow Privacy is installed.\")\n",
    "except ImportError:\n",
    "    print(\"TensorFlow Privacy is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95284ea-eb47-4240-b321-11af13d54afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Nov_18_09:45:30_PST_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.119\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\n",
      "Mon Sep  9 22:49:25 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8               9W / 250W |   9965MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   30C    P8               1W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8              17W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8              22W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8               4W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8               1W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8               5W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:41:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8               4W / 250W |   9963MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fbe89c-7620-430e-be4a-d66a01c42e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2ff383-b954-4fda-a59b-86813dcb7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_privacy import DPKerasAdamOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf770e4-51de-4690-bdc5-9aa02dc54f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 22:49:47.642841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 510 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.644597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 512 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.646025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 512 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1d:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.647341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 512 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1e:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.648667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 512 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.650108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 512 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.651304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 512 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3f:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:47.652423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 512 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5\n",
      "2024-09-09 22:49:54.888772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc2c0017410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-09 22:49:54.888830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888842: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888852: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888861: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888880: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888889: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.888898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-09-09 22:49:54.895610: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-09 22:49:54.963649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-09-09 22:49:55.110814: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Generator Loss: -0.7078, Critic Loss: -0.9357\n",
      "Epoch 2/500, Generator Loss: 1.3317, Critic Loss: -0.2023\n",
      "Epoch 3/500, Generator Loss: 0.5531, Critic Loss: -0.8348\n",
      "Epoch 4/500, Generator Loss: 0.6499, Critic Loss: -0.7195\n",
      "Epoch 5/500, Generator Loss: 0.5593, Critic Loss: -0.6168\n",
      "Epoch 6/500, Generator Loss: 0.4094, Critic Loss: -0.3883\n",
      "Epoch 7/500, Generator Loss: 0.3663, Critic Loss: -0.4992\n",
      "Epoch 8/500, Generator Loss: 0.4315, Critic Loss: -0.4226\n",
      "Epoch 9/500, Generator Loss: 0.2106, Critic Loss: -0.3854\n",
      "Epoch 10/500, Generator Loss: 0.1852, Critic Loss: -0.3380\n",
      "Epoch 11/500, Generator Loss: 0.4944, Critic Loss: -0.3707\n",
      "Epoch 12/500, Generator Loss: 0.1245, Critic Loss: -0.3192\n",
      "Epoch 13/500, Generator Loss: 0.2529, Critic Loss: -0.1146\n",
      "Epoch 14/500, Generator Loss: 0.3874, Critic Loss: -0.2754\n",
      "Epoch 15/500, Generator Loss: 0.2980, Critic Loss: -0.3155\n",
      "Epoch 16/500, Generator Loss: 0.1011, Critic Loss: -0.2233\n",
      "Epoch 17/500, Generator Loss: 0.1482, Critic Loss: -0.2404\n",
      "Epoch 18/500, Generator Loss: 0.2055, Critic Loss: -0.2590\n",
      "Epoch 19/500, Generator Loss: 0.3365, Critic Loss: -0.1867\n",
      "Epoch 20/500, Generator Loss: 0.1675, Critic Loss: -0.1569\n",
      "Epoch 21/500, Generator Loss: 0.1594, Critic Loss: -0.2205\n",
      "Epoch 22/500, Generator Loss: 0.1831, Critic Loss: -0.2172\n",
      "Epoch 23/500, Generator Loss: 0.1881, Critic Loss: -0.2045\n",
      "Epoch 24/500, Generator Loss: 0.1775, Critic Loss: -0.1941\n",
      "Epoch 25/500, Generator Loss: 0.1426, Critic Loss: -0.1593\n",
      "Epoch 26/500, Generator Loss: 0.1895, Critic Loss: -0.1697\n",
      "Epoch 27/500, Generator Loss: 0.1746, Critic Loss: -0.1470\n",
      "Epoch 28/500, Generator Loss: 0.2203, Critic Loss: -0.1828\n",
      "Epoch 29/500, Generator Loss: 0.1983, Critic Loss: -0.1684\n",
      "Epoch 30/500, Generator Loss: 0.1777, Critic Loss: -0.1095\n",
      "Epoch 31/500, Generator Loss: 0.1813, Critic Loss: -0.0977\n",
      "Epoch 32/500, Generator Loss: 0.2099, Critic Loss: -0.1065\n",
      "Epoch 33/500, Generator Loss: 0.1864, Critic Loss: -0.1481\n",
      "Epoch 34/500, Generator Loss: 0.1878, Critic Loss: -0.1044\n",
      "Epoch 35/500, Generator Loss: 0.1618, Critic Loss: 0.0015\n",
      "Epoch 36/500, Generator Loss: 0.1563, Critic Loss: -0.0913\n",
      "Epoch 37/500, Generator Loss: 0.1550, Critic Loss: -0.0818\n",
      "Epoch 38/500, Generator Loss: 0.2036, Critic Loss: -0.1217\n",
      "Epoch 39/500, Generator Loss: 0.1881, Critic Loss: -0.0810\n",
      "Epoch 40/500, Generator Loss: 0.2146, Critic Loss: -0.0859\n",
      "Epoch 41/500, Generator Loss: 0.1968, Critic Loss: 0.0271\n",
      "Epoch 42/500, Generator Loss: 0.2160, Critic Loss: -0.0329\n",
      "Epoch 43/500, Generator Loss: 0.1521, Critic Loss: 0.0670\n",
      "Epoch 44/500, Generator Loss: 0.1499, Critic Loss: -0.0265\n",
      "Epoch 45/500, Generator Loss: 0.1727, Critic Loss: 0.0671\n",
      "Epoch 46/500, Generator Loss: 0.1691, Critic Loss: -0.0323\n",
      "Epoch 47/500, Generator Loss: 0.1650, Critic Loss: -0.0237\n",
      "Epoch 48/500, Generator Loss: 0.1780, Critic Loss: -0.0490\n",
      "Epoch 49/500, Generator Loss: 0.1077, Critic Loss: -0.0445\n",
      "Epoch 50/500, Generator Loss: 0.1614, Critic Loss: 0.0210\n",
      "Epoch 51/500, Generator Loss: 0.0979, Critic Loss: 0.0905\n",
      "Epoch 52/500, Generator Loss: 0.1492, Critic Loss: -0.0423\n",
      "Epoch 53/500, Generator Loss: 0.1271, Critic Loss: -0.0444\n",
      "Epoch 54/500, Generator Loss: 0.1423, Critic Loss: -0.0339\n",
      "Epoch 55/500, Generator Loss: 0.1387, Critic Loss: 0.0441\n",
      "Epoch 56/500, Generator Loss: 0.1072, Critic Loss: -0.0068\n",
      "Epoch 57/500, Generator Loss: 0.1455, Critic Loss: 0.0257\n",
      "Epoch 58/500, Generator Loss: 0.1495, Critic Loss: -0.0265\n",
      "Epoch 59/500, Generator Loss: 0.1226, Critic Loss: -0.0145\n",
      "Epoch 60/500, Generator Loss: 0.1512, Critic Loss: 0.0245\n",
      "Epoch 61/500, Generator Loss: 0.1120, Critic Loss: 0.0177\n",
      "Epoch 62/500, Generator Loss: 0.0777, Critic Loss: 0.0086\n",
      "Epoch 63/500, Generator Loss: 0.1323, Critic Loss: -0.0068\n",
      "Epoch 64/500, Generator Loss: 0.1158, Critic Loss: 0.0138\n",
      "Epoch 65/500, Generator Loss: 0.0603, Critic Loss: 0.0474\n",
      "Epoch 66/500, Generator Loss: 0.0590, Critic Loss: 0.0246\n",
      "Epoch 67/500, Generator Loss: 0.0464, Critic Loss: -0.0095\n",
      "Epoch 68/500, Generator Loss: 0.0486, Critic Loss: -0.0015\n",
      "Epoch 69/500, Generator Loss: 0.0466, Critic Loss: -0.0238\n",
      "Epoch 70/500, Generator Loss: 0.0265, Critic Loss: 0.0057\n",
      "Epoch 71/500, Generator Loss: 0.0005, Critic Loss: -0.0304\n",
      "Epoch 72/500, Generator Loss: 0.0074, Critic Loss: 0.0104\n",
      "Epoch 73/500, Generator Loss: -0.0070, Critic Loss: -0.0426\n",
      "Epoch 74/500, Generator Loss: -0.0017, Critic Loss: -0.0026\n",
      "Epoch 75/500, Generator Loss: -0.0026, Critic Loss: -0.0410\n",
      "Epoch 76/500, Generator Loss: -0.0191, Critic Loss: -0.0260\n",
      "Epoch 77/500, Generator Loss: 0.0451, Critic Loss: 0.0035\n",
      "Epoch 78/500, Generator Loss: -0.0115, Critic Loss: -0.0239\n",
      "Epoch 79/500, Generator Loss: 0.0055, Critic Loss: -0.0312\n",
      "Epoch 80/500, Generator Loss: -0.0079, Critic Loss: -0.0097\n",
      "Epoch 81/500, Generator Loss: -0.0239, Critic Loss: -0.0102\n",
      "Epoch 82/500, Generator Loss: -0.0321, Critic Loss: -0.0363\n",
      "Epoch 83/500, Generator Loss: -0.0183, Critic Loss: 0.0128\n",
      "Epoch 84/500, Generator Loss: -0.0285, Critic Loss: -0.0210\n",
      "Epoch 85/500, Generator Loss: -0.0276, Critic Loss: -0.0227\n",
      "Epoch 86/500, Generator Loss: -0.0132, Critic Loss: -0.0300\n",
      "Epoch 87/500, Generator Loss: -0.0234, Critic Loss: -0.0322\n",
      "Epoch 88/500, Generator Loss: -0.0310, Critic Loss: -0.0281\n",
      "Epoch 89/500, Generator Loss: -0.0484, Critic Loss: -0.0205\n",
      "Epoch 90/500, Generator Loss: -0.0413, Critic Loss: -0.0293\n",
      "Epoch 91/500, Generator Loss: -0.0318, Critic Loss: -0.0366\n",
      "Epoch 92/500, Generator Loss: -0.0825, Critic Loss: -0.0282\n",
      "Epoch 93/500, Generator Loss: -0.0031, Critic Loss: -0.0215\n",
      "Epoch 94/500, Generator Loss: -0.0565, Critic Loss: -0.0280\n",
      "Epoch 95/500, Generator Loss: -0.0777, Critic Loss: -0.0258\n",
      "Epoch 96/500, Generator Loss: -0.0659, Critic Loss: -0.0266\n",
      "Epoch 97/500, Generator Loss: -0.1010, Critic Loss: -0.0234\n",
      "Epoch 98/500, Generator Loss: -0.0704, Critic Loss: -0.0113\n",
      "Epoch 99/500, Generator Loss: -0.0472, Critic Loss: -0.0198\n",
      "Epoch 100/500, Generator Loss: -0.0852, Critic Loss: -0.0258\n",
      "Epoch 101/500, Generator Loss: -0.0582, Critic Loss: -0.0179\n",
      "Epoch 102/500, Generator Loss: -0.0680, Critic Loss: -0.0227\n",
      "Epoch 103/500, Generator Loss: -0.0809, Critic Loss: -0.0228\n",
      "Epoch 104/500, Generator Loss: -0.0496, Critic Loss: -0.0248\n",
      "Epoch 105/500, Generator Loss: -0.0917, Critic Loss: -0.0211\n",
      "Epoch 106/500, Generator Loss: -0.0458, Critic Loss: -0.0283\n",
      "Epoch 107/500, Generator Loss: -0.0671, Critic Loss: -0.0321\n",
      "Epoch 108/500, Generator Loss: -0.0826, Critic Loss: -0.0276\n",
      "Epoch 109/500, Generator Loss: -0.0655, Critic Loss: -0.0190\n",
      "Epoch 110/500, Generator Loss: -0.0666, Critic Loss: -0.0222\n",
      "Epoch 111/500, Generator Loss: -0.0731, Critic Loss: -0.0223\n",
      "Epoch 112/500, Generator Loss: -0.0705, Critic Loss: -0.0229\n",
      "Epoch 113/500, Generator Loss: -0.0799, Critic Loss: -0.0247\n",
      "Epoch 114/500, Generator Loss: -0.1016, Critic Loss: -0.0204\n",
      "Epoch 115/500, Generator Loss: -0.0577, Critic Loss: -0.0119\n",
      "Epoch 116/500, Generator Loss: -0.0274, Critic Loss: -0.0251\n",
      "Epoch 117/500, Generator Loss: -0.0567, Critic Loss: -0.0234\n",
      "Epoch 118/500, Generator Loss: -0.0524, Critic Loss: -0.0210\n",
      "Epoch 119/500, Generator Loss: -0.0479, Critic Loss: -0.0209\n",
      "Epoch 120/500, Generator Loss: -0.0772, Critic Loss: -0.0229\n",
      "Epoch 121/500, Generator Loss: -0.0570, Critic Loss: -0.0319\n",
      "Epoch 122/500, Generator Loss: -0.0572, Critic Loss: -0.0263\n",
      "Epoch 123/500, Generator Loss: -0.0772, Critic Loss: -0.0226\n",
      "Epoch 124/500, Generator Loss: -0.0653, Critic Loss: -0.0213\n",
      "Epoch 125/500, Generator Loss: -0.0542, Critic Loss: -0.0160\n",
      "Epoch 126/500, Generator Loss: -0.0393, Critic Loss: -0.0207\n",
      "Epoch 127/500, Generator Loss: -0.0608, Critic Loss: -0.0175\n",
      "Epoch 128/500, Generator Loss: -0.0074, Critic Loss: -0.0282\n",
      "Epoch 129/500, Generator Loss: -0.0551, Critic Loss: -0.0156\n",
      "Epoch 130/500, Generator Loss: -0.0363, Critic Loss: -0.0259\n",
      "Epoch 131/500, Generator Loss: -0.0331, Critic Loss: -0.0173\n",
      "Epoch 132/500, Generator Loss: -0.0218, Critic Loss: -0.0218\n",
      "Epoch 133/500, Generator Loss: 0.0159, Critic Loss: -0.0150\n",
      "Epoch 134/500, Generator Loss: -0.0003, Critic Loss: -0.0187\n",
      "Epoch 135/500, Generator Loss: -0.0536, Critic Loss: -0.0234\n",
      "Epoch 136/500, Generator Loss: -0.0411, Critic Loss: -0.0249\n",
      "Epoch 137/500, Generator Loss: -0.0185, Critic Loss: -0.0188\n",
      "Epoch 138/500, Generator Loss: -0.0049, Critic Loss: -0.0206\n",
      "Epoch 139/500, Generator Loss: -0.0139, Critic Loss: -0.0161\n",
      "Epoch 140/500, Generator Loss: -0.0047, Critic Loss: -0.0204\n",
      "Epoch 141/500, Generator Loss: 0.0158, Critic Loss: -0.0203\n",
      "Epoch 142/500, Generator Loss: -0.0213, Critic Loss: -0.0171\n",
      "Epoch 143/500, Generator Loss: -0.0020, Critic Loss: -0.0103\n",
      "Epoch 144/500, Generator Loss: 0.0065, Critic Loss: -0.0294\n",
      "Epoch 145/500, Generator Loss: -0.0215, Critic Loss: -0.0219\n",
      "Epoch 146/500, Generator Loss: 0.0208, Critic Loss: -0.0235\n",
      "Epoch 147/500, Generator Loss: 0.0199, Critic Loss: -0.0172\n",
      "Epoch 148/500, Generator Loss: -0.0092, Critic Loss: -0.0285\n",
      "Epoch 149/500, Generator Loss: 0.0043, Critic Loss: -0.0246\n",
      "Epoch 150/500, Generator Loss: 0.0017, Critic Loss: -0.0234\n",
      "Epoch 151/500, Generator Loss: 0.0227, Critic Loss: -0.0218\n",
      "Epoch 152/500, Generator Loss: 0.0079, Critic Loss: -0.0169\n",
      "Epoch 153/500, Generator Loss: 0.0075, Critic Loss: -0.0215\n",
      "Epoch 154/500, Generator Loss: -0.0034, Critic Loss: -0.0190\n",
      "Epoch 155/500, Generator Loss: 0.0283, Critic Loss: -0.0205\n",
      "Epoch 156/500, Generator Loss: 0.0402, Critic Loss: -0.0153\n",
      "Epoch 157/500, Generator Loss: 0.0018, Critic Loss: -0.0188\n",
      "Epoch 158/500, Generator Loss: 0.0384, Critic Loss: -0.0202\n",
      "Epoch 159/500, Generator Loss: 0.0265, Critic Loss: -0.0183\n",
      "Epoch 160/500, Generator Loss: 0.0275, Critic Loss: -0.0192\n",
      "Epoch 161/500, Generator Loss: 0.0459, Critic Loss: -0.0209\n",
      "Epoch 162/500, Generator Loss: 0.0590, Critic Loss: -0.0230\n",
      "Epoch 163/500, Generator Loss: 0.0647, Critic Loss: -0.0186\n",
      "Epoch 164/500, Generator Loss: 0.0261, Critic Loss: -0.0224\n",
      "Epoch 165/500, Generator Loss: 0.0286, Critic Loss: -0.0160\n",
      "Epoch 166/500, Generator Loss: 0.0329, Critic Loss: -0.0170\n",
      "Epoch 167/500, Generator Loss: 0.0673, Critic Loss: -0.0211\n",
      "Epoch 168/500, Generator Loss: 0.0110, Critic Loss: -0.0150\n",
      "Epoch 169/500, Generator Loss: 0.0330, Critic Loss: -0.0194\n",
      "Epoch 170/500, Generator Loss: 0.0351, Critic Loss: -0.0203\n",
      "Epoch 171/500, Generator Loss: 0.0862, Critic Loss: -0.0265\n",
      "Epoch 172/500, Generator Loss: 0.0604, Critic Loss: -0.0194\n",
      "Epoch 173/500, Generator Loss: 0.0632, Critic Loss: -0.0190\n",
      "Epoch 174/500, Generator Loss: 0.0672, Critic Loss: -0.0188\n",
      "Epoch 175/500, Generator Loss: 0.0795, Critic Loss: -0.0224\n",
      "Epoch 176/500, Generator Loss: 0.0787, Critic Loss: -0.0198\n",
      "Epoch 177/500, Generator Loss: 0.0554, Critic Loss: -0.0181\n",
      "Epoch 178/500, Generator Loss: 0.0760, Critic Loss: -0.0174\n",
      "Epoch 179/500, Generator Loss: 0.1011, Critic Loss: -0.0160\n",
      "Epoch 180/500, Generator Loss: 0.0736, Critic Loss: -0.0167\n",
      "Epoch 181/500, Generator Loss: 0.0886, Critic Loss: -0.0147\n",
      "Epoch 182/500, Generator Loss: 0.1154, Critic Loss: -0.0174\n",
      "Epoch 183/500, Generator Loss: 0.1010, Critic Loss: -0.0194\n",
      "Epoch 184/500, Generator Loss: 0.0952, Critic Loss: -0.0092\n",
      "Epoch 185/500, Generator Loss: 0.0991, Critic Loss: -0.0225\n",
      "Epoch 186/500, Generator Loss: 0.1224, Critic Loss: -0.0166\n",
      "Epoch 187/500, Generator Loss: 0.1284, Critic Loss: -0.0185\n",
      "Epoch 188/500, Generator Loss: 0.0731, Critic Loss: -0.0168\n",
      "Epoch 189/500, Generator Loss: 0.1104, Critic Loss: -0.0177\n",
      "Epoch 190/500, Generator Loss: 0.1251, Critic Loss: -0.0020\n",
      "Epoch 191/500, Generator Loss: 0.1143, Critic Loss: -0.0178\n",
      "Epoch 192/500, Generator Loss: 0.1004, Critic Loss: -0.0112\n",
      "Epoch 193/500, Generator Loss: 0.1008, Critic Loss: -0.0171\n",
      "Epoch 194/500, Generator Loss: 0.1094, Critic Loss: -0.0210\n",
      "Epoch 195/500, Generator Loss: 0.1119, Critic Loss: -0.0196\n",
      "Epoch 196/500, Generator Loss: 0.1243, Critic Loss: -0.0179\n",
      "Epoch 197/500, Generator Loss: 0.1202, Critic Loss: -0.0146\n",
      "Epoch 198/500, Generator Loss: 0.1439, Critic Loss: -0.0290\n",
      "Epoch 199/500, Generator Loss: 0.1337, Critic Loss: -0.0181\n",
      "Epoch 200/500, Generator Loss: 0.1185, Critic Loss: -0.0163\n",
      "Epoch 201/500, Generator Loss: 0.0970, Critic Loss: -0.0147\n",
      "Epoch 202/500, Generator Loss: 0.1018, Critic Loss: -0.0117\n",
      "Epoch 203/500, Generator Loss: 0.0992, Critic Loss: -0.0186\n",
      "Epoch 204/500, Generator Loss: 0.0532, Critic Loss: -0.0143\n",
      "Epoch 205/500, Generator Loss: 0.0697, Critic Loss: -0.0175\n",
      "Epoch 206/500, Generator Loss: 0.0674, Critic Loss: -0.0114\n",
      "Epoch 207/500, Generator Loss: 0.0975, Critic Loss: -0.0162\n",
      "Epoch 208/500, Generator Loss: 0.0651, Critic Loss: -0.0116\n",
      "Epoch 209/500, Generator Loss: 0.1014, Critic Loss: -0.0143\n",
      "Epoch 210/500, Generator Loss: 0.0701, Critic Loss: -0.0175\n",
      "Epoch 211/500, Generator Loss: 0.1392, Critic Loss: -0.0040\n",
      "Epoch 212/500, Generator Loss: 0.1161, Critic Loss: -0.0147\n",
      "Epoch 213/500, Generator Loss: 0.0874, Critic Loss: -0.0109\n",
      "Epoch 214/500, Generator Loss: 0.1155, Critic Loss: -0.0173\n",
      "Epoch 215/500, Generator Loss: 0.0935, Critic Loss: -0.0141\n",
      "Epoch 216/500, Generator Loss: 0.1211, Critic Loss: -0.0108\n",
      "Epoch 217/500, Generator Loss: 0.1103, Critic Loss: -0.0113\n",
      "Epoch 218/500, Generator Loss: 0.1335, Critic Loss: -0.0098\n",
      "Epoch 219/500, Generator Loss: 0.1240, Critic Loss: -0.0141\n",
      "Epoch 220/500, Generator Loss: 0.1257, Critic Loss: -0.0141\n",
      "Epoch 221/500, Generator Loss: 0.1555, Critic Loss: -0.0177\n",
      "Epoch 222/500, Generator Loss: 0.1396, Critic Loss: -0.0134\n",
      "Epoch 223/500, Generator Loss: 0.1252, Critic Loss: -0.0100\n",
      "Epoch 224/500, Generator Loss: 0.1326, Critic Loss: -0.0121\n",
      "Epoch 225/500, Generator Loss: 0.1508, Critic Loss: -0.0101\n",
      "Epoch 226/500, Generator Loss: 0.1419, Critic Loss: -0.0135\n",
      "Epoch 227/500, Generator Loss: 0.1678, Critic Loss: -0.0119\n",
      "Epoch 228/500, Generator Loss: 0.1509, Critic Loss: -0.0166\n",
      "Epoch 229/500, Generator Loss: 0.1317, Critic Loss: -0.0105\n",
      "Epoch 230/500, Generator Loss: 0.1636, Critic Loss: -0.0197\n",
      "Epoch 231/500, Generator Loss: 0.1668, Critic Loss: -0.0114\n",
      "Epoch 232/500, Generator Loss: 0.1858, Critic Loss: -0.0357\n",
      "Epoch 233/500, Generator Loss: 0.1389, Critic Loss: -0.0118\n",
      "Epoch 234/500, Generator Loss: 0.1726, Critic Loss: -0.0140\n",
      "Epoch 235/500, Generator Loss: 0.1744, Critic Loss: -0.0108\n",
      "Epoch 236/500, Generator Loss: 0.1669, Critic Loss: -0.0163\n",
      "Epoch 237/500, Generator Loss: 0.1749, Critic Loss: -0.0163\n",
      "Epoch 238/500, Generator Loss: 0.1750, Critic Loss: -0.0149\n",
      "Epoch 239/500, Generator Loss: 0.1509, Critic Loss: -0.0100\n",
      "Epoch 240/500, Generator Loss: 0.1432, Critic Loss: -0.0131\n",
      "Epoch 241/500, Generator Loss: 0.1495, Critic Loss: -0.0077\n",
      "Epoch 242/500, Generator Loss: 0.1544, Critic Loss: -0.0132\n",
      "Epoch 243/500, Generator Loss: 0.1314, Critic Loss: -0.0134\n",
      "Epoch 244/500, Generator Loss: 0.1394, Critic Loss: -0.0086\n",
      "Epoch 245/500, Generator Loss: 0.1213, Critic Loss: -0.0111\n",
      "Epoch 246/500, Generator Loss: 0.1709, Critic Loss: -0.0112\n",
      "Epoch 247/500, Generator Loss: 0.1660, Critic Loss: -0.0220\n",
      "Epoch 248/500, Generator Loss: 0.1070, Critic Loss: -0.0125\n",
      "Epoch 249/500, Generator Loss: 0.1535, Critic Loss: -0.0193\n",
      "Epoch 250/500, Generator Loss: 0.1404, Critic Loss: -0.0123\n",
      "Epoch 251/500, Generator Loss: 0.1551, Critic Loss: -0.0156\n",
      "Epoch 252/500, Generator Loss: 0.1213, Critic Loss: -0.0142\n",
      "Epoch 253/500, Generator Loss: 0.1385, Critic Loss: -0.0104\n",
      "Epoch 254/500, Generator Loss: 0.1433, Critic Loss: -0.0138\n",
      "Epoch 255/500, Generator Loss: 0.1653, Critic Loss: -0.0065\n",
      "Epoch 256/500, Generator Loss: 0.1592, Critic Loss: -0.0155\n",
      "Epoch 257/500, Generator Loss: 0.1430, Critic Loss: 0.0043\n",
      "Epoch 258/500, Generator Loss: 0.1859, Critic Loss: -0.0130\n",
      "Epoch 259/500, Generator Loss: 0.1358, Critic Loss: -0.0155\n",
      "Epoch 260/500, Generator Loss: 0.1481, Critic Loss: -0.0175\n",
      "Epoch 261/500, Generator Loss: 0.1241, Critic Loss: -0.0052\n",
      "Epoch 262/500, Generator Loss: 0.0544, Critic Loss: -0.0191\n",
      "Epoch 263/500, Generator Loss: 0.1461, Critic Loss: -0.0117\n",
      "Epoch 264/500, Generator Loss: 0.1119, Critic Loss: -0.0100\n",
      "Epoch 265/500, Generator Loss: 0.1078, Critic Loss: -0.0033\n",
      "Epoch 266/500, Generator Loss: 0.1851, Critic Loss: -0.0244\n",
      "Epoch 267/500, Generator Loss: 0.1933, Critic Loss: -0.0125\n",
      "Epoch 268/500, Generator Loss: 0.1138, Critic Loss: -0.0176\n",
      "Epoch 269/500, Generator Loss: 0.0906, Critic Loss: -0.0128\n",
      "Epoch 270/500, Generator Loss: 0.1359, Critic Loss: -0.0079\n",
      "Epoch 271/500, Generator Loss: 0.1506, Critic Loss: -0.0068\n",
      "Epoch 272/500, Generator Loss: 0.1537, Critic Loss: -0.0033\n",
      "Epoch 273/500, Generator Loss: 0.1684, Critic Loss: -0.0134\n",
      "Epoch 274/500, Generator Loss: 0.1983, Critic Loss: -0.0095\n",
      "Epoch 275/500, Generator Loss: 0.1315, Critic Loss: -0.0072\n",
      "Epoch 276/500, Generator Loss: 0.1776, Critic Loss: -0.0123\n",
      "Epoch 277/500, Generator Loss: 0.1496, Critic Loss: -0.0131\n",
      "Epoch 278/500, Generator Loss: 0.0910, Critic Loss: -0.0072\n",
      "Epoch 279/500, Generator Loss: 0.1078, Critic Loss: -0.0166\n",
      "Epoch 280/500, Generator Loss: 0.1266, Critic Loss: -0.0162\n",
      "Epoch 281/500, Generator Loss: 0.1454, Critic Loss: -0.0181\n",
      "Epoch 282/500, Generator Loss: 0.1223, Critic Loss: -0.0090\n",
      "Epoch 283/500, Generator Loss: 0.1328, Critic Loss: -0.0108\n",
      "Epoch 284/500, Generator Loss: 0.1073, Critic Loss: -0.0099\n",
      "Epoch 285/500, Generator Loss: 0.0936, Critic Loss: -0.0096\n",
      "Epoch 286/500, Generator Loss: 0.1397, Critic Loss: -0.0118\n",
      "Epoch 287/500, Generator Loss: 0.0950, Critic Loss: -0.0105\n",
      "Epoch 288/500, Generator Loss: 0.1250, Critic Loss: -0.0141\n",
      "Epoch 289/500, Generator Loss: 0.0723, Critic Loss: -0.0055\n",
      "Epoch 290/500, Generator Loss: 0.0937, Critic Loss: -0.0088\n",
      "Epoch 291/500, Generator Loss: 0.0714, Critic Loss: -0.0128\n",
      "Epoch 292/500, Generator Loss: 0.1199, Critic Loss: -0.0089\n",
      "Epoch 293/500, Generator Loss: 0.1163, Critic Loss: -0.0140\n",
      "Epoch 294/500, Generator Loss: 0.1286, Critic Loss: -0.0108\n",
      "Epoch 295/500, Generator Loss: 0.0785, Critic Loss: -0.0130\n",
      "Epoch 296/500, Generator Loss: 0.0782, Critic Loss: -0.0039\n",
      "Epoch 297/500, Generator Loss: 0.0834, Critic Loss: -0.0060\n",
      "Epoch 298/500, Generator Loss: 0.0823, Critic Loss: -0.0138\n",
      "Epoch 299/500, Generator Loss: 0.0703, Critic Loss: -0.0193\n",
      "Epoch 300/500, Generator Loss: 0.0939, Critic Loss: -0.0351\n",
      "Epoch 301/500, Generator Loss: 0.0744, Critic Loss: -0.0092\n",
      "Epoch 302/500, Generator Loss: 0.0568, Critic Loss: -0.0156\n",
      "Epoch 303/500, Generator Loss: 0.0726, Critic Loss: -0.0146\n",
      "Epoch 304/500, Generator Loss: 0.0378, Critic Loss: -0.0112\n",
      "Epoch 305/500, Generator Loss: 0.0874, Critic Loss: -0.0090\n",
      "Epoch 306/500, Generator Loss: 0.0266, Critic Loss: -0.0048\n",
      "Epoch 307/500, Generator Loss: 0.1124, Critic Loss: -0.0457\n",
      "Epoch 308/500, Generator Loss: -0.1188, Critic Loss: -0.0034\n",
      "Epoch 309/500, Generator Loss: -0.1099, Critic Loss: -0.0194\n",
      "Epoch 310/500, Generator Loss: -0.0687, Critic Loss: -0.0075\n",
      "Epoch 311/500, Generator Loss: -0.0883, Critic Loss: -0.0098\n",
      "Epoch 312/500, Generator Loss: -0.0974, Critic Loss: -0.0144\n",
      "Epoch 313/500, Generator Loss: -0.1125, Critic Loss: -0.0136\n",
      "Epoch 314/500, Generator Loss: -0.1116, Critic Loss: -0.0138\n",
      "Epoch 315/500, Generator Loss: -0.0898, Critic Loss: -0.0070\n",
      "Epoch 316/500, Generator Loss: -0.1130, Critic Loss: -0.0218\n",
      "Epoch 317/500, Generator Loss: -0.0391, Critic Loss: -0.0131\n",
      "Epoch 318/500, Generator Loss: -0.0213, Critic Loss: -0.0065\n",
      "Epoch 319/500, Generator Loss: -0.0725, Critic Loss: -0.0122\n",
      "Epoch 320/500, Generator Loss: -0.0196, Critic Loss: -0.0127\n",
      "Epoch 321/500, Generator Loss: -0.0755, Critic Loss: -0.0121\n",
      "Epoch 322/500, Generator Loss: -0.0552, Critic Loss: -0.0037\n",
      "Epoch 323/500, Generator Loss: 0.0036, Critic Loss: -0.0093\n",
      "Epoch 324/500, Generator Loss: -0.0415, Critic Loss: -0.0144\n",
      "Epoch 325/500, Generator Loss: -0.0744, Critic Loss: -0.0153\n",
      "Epoch 326/500, Generator Loss: -0.0420, Critic Loss: -0.0147\n",
      "Epoch 327/500, Generator Loss: -0.0045, Critic Loss: -0.0158\n",
      "Epoch 328/500, Generator Loss: -0.0300, Critic Loss: -0.0114\n",
      "Epoch 329/500, Generator Loss: -0.0935, Critic Loss: -0.0136\n",
      "Epoch 330/500, Generator Loss: -0.0184, Critic Loss: -0.0050\n",
      "Epoch 331/500, Generator Loss: -0.0588, Critic Loss: -0.0121\n",
      "Epoch 332/500, Generator Loss: -0.0186, Critic Loss: -0.0000\n",
      "Epoch 333/500, Generator Loss: -0.0275, Critic Loss: 0.0163\n",
      "Epoch 334/500, Generator Loss: -0.1001, Critic Loss: -0.0017\n",
      "Epoch 335/500, Generator Loss: -0.0504, Critic Loss: -0.0103\n",
      "Epoch 336/500, Generator Loss: -0.0347, Critic Loss: -0.0065\n",
      "Epoch 337/500, Generator Loss: -0.0452, Critic Loss: -0.0175\n",
      "Epoch 338/500, Generator Loss: -0.0700, Critic Loss: 0.0060\n",
      "Epoch 339/500, Generator Loss: -0.0377, Critic Loss: -0.0038\n",
      "Epoch 340/500, Generator Loss: -0.0360, Critic Loss: -0.0095\n",
      "Epoch 341/500, Generator Loss: -0.0382, Critic Loss: -0.0059\n",
      "Epoch 342/500, Generator Loss: -0.1135, Critic Loss: -0.0076\n",
      "Epoch 343/500, Generator Loss: 0.0175, Critic Loss: -0.0182\n",
      "Epoch 344/500, Generator Loss: -0.0480, Critic Loss: -0.0095\n",
      "Epoch 345/500, Generator Loss: -0.0593, Critic Loss: -0.0035\n",
      "Epoch 346/500, Generator Loss: -0.0293, Critic Loss: -0.0108\n",
      "Epoch 347/500, Generator Loss: -0.0531, Critic Loss: -0.0173\n",
      "Epoch 348/500, Generator Loss: -0.0427, Critic Loss: -0.0081\n",
      "Epoch 349/500, Generator Loss: -0.0105, Critic Loss: -0.0051\n",
      "Epoch 350/500, Generator Loss: -0.0269, Critic Loss: -0.0124\n",
      "Epoch 351/500, Generator Loss: -0.0515, Critic Loss: -0.0086\n",
      "Epoch 352/500, Generator Loss: -0.0299, Critic Loss: -0.0154\n",
      "Epoch 353/500, Generator Loss: -0.0511, Critic Loss: -0.0133\n",
      "Epoch 354/500, Generator Loss: -0.0037, Critic Loss: -0.0134\n",
      "Epoch 355/500, Generator Loss: -0.0872, Critic Loss: 0.0050\n",
      "Epoch 356/500, Generator Loss: -0.0352, Critic Loss: -0.0138\n",
      "Epoch 357/500, Generator Loss: -0.0235, Critic Loss: -0.0110\n",
      "Epoch 358/500, Generator Loss: -0.0086, Critic Loss: 0.0027\n",
      "Epoch 359/500, Generator Loss: -0.0195, Critic Loss: -0.0051\n",
      "Epoch 360/500, Generator Loss: 0.0303, Critic Loss: -0.0154\n",
      "Epoch 361/500, Generator Loss: -0.0422, Critic Loss: -0.0145\n",
      "Epoch 362/500, Generator Loss: 0.0648, Critic Loss: -0.0108\n",
      "Epoch 363/500, Generator Loss: 0.0245, Critic Loss: -0.0082\n",
      "Epoch 364/500, Generator Loss: 0.0454, Critic Loss: -0.0048\n",
      "Epoch 365/500, Generator Loss: 0.0125, Critic Loss: 0.0008\n",
      "Epoch 366/500, Generator Loss: -0.0191, Critic Loss: -0.0128\n",
      "Epoch 367/500, Generator Loss: -0.0395, Critic Loss: -0.0074\n",
      "Epoch 368/500, Generator Loss: -0.0677, Critic Loss: -0.0127\n",
      "Epoch 369/500, Generator Loss: -0.0217, Critic Loss: -0.0113\n",
      "Epoch 370/500, Generator Loss: -0.0057, Critic Loss: -0.0154\n",
      "Epoch 371/500, Generator Loss: -0.0008, Critic Loss: -0.0122\n",
      "Epoch 372/500, Generator Loss: 0.0554, Critic Loss: -0.0233\n",
      "Epoch 373/500, Generator Loss: -0.0833, Critic Loss: -0.0072\n",
      "Epoch 374/500, Generator Loss: -0.0106, Critic Loss: -0.0093\n",
      "Epoch 375/500, Generator Loss: -0.1102, Critic Loss: -0.0019\n",
      "Epoch 376/500, Generator Loss: -0.0014, Critic Loss: -0.0212\n",
      "Epoch 377/500, Generator Loss: -0.0042, Critic Loss: -0.0028\n",
      "Epoch 378/500, Generator Loss: 0.0315, Critic Loss: -0.0103\n",
      "Epoch 379/500, Generator Loss: -0.0866, Critic Loss: -0.0048\n",
      "Epoch 380/500, Generator Loss: 0.0246, Critic Loss: -0.0083\n",
      "Epoch 381/500, Generator Loss: 0.0083, Critic Loss: -0.0143\n",
      "Epoch 382/500, Generator Loss: -0.0804, Critic Loss: -0.0007\n",
      "Epoch 383/500, Generator Loss: 0.0494, Critic Loss: -0.0071\n",
      "Epoch 384/500, Generator Loss: 0.0912, Critic Loss: -0.0166\n",
      "Epoch 385/500, Generator Loss: -0.0036, Critic Loss: -0.0061\n",
      "Epoch 386/500, Generator Loss: 0.0211, Critic Loss: -0.0118\n",
      "Epoch 387/500, Generator Loss: 0.0416, Critic Loss: -0.0132\n",
      "Epoch 388/500, Generator Loss: -0.0313, Critic Loss: -0.0079\n",
      "Epoch 389/500, Generator Loss: 0.0337, Critic Loss: -0.0129\n",
      "Epoch 390/500, Generator Loss: 0.0458, Critic Loss: -0.0091\n",
      "Epoch 391/500, Generator Loss: -0.0459, Critic Loss: -0.0067\n",
      "Epoch 392/500, Generator Loss: 0.0625, Critic Loss: -0.0437\n",
      "Epoch 393/500, Generator Loss: 0.1373, Critic Loss: -0.0194\n",
      "Epoch 394/500, Generator Loss: -0.0364, Critic Loss: -0.0082\n",
      "Epoch 395/500, Generator Loss: 0.0412, Critic Loss: 0.0046\n",
      "Epoch 396/500, Generator Loss: 0.0652, Critic Loss: -0.0140\n",
      "Epoch 397/500, Generator Loss: 0.0351, Critic Loss: -0.0106\n",
      "Epoch 398/500, Generator Loss: 0.0424, Critic Loss: -0.0063\n",
      "Epoch 399/500, Generator Loss: 0.0611, Critic Loss: -0.0041\n",
      "Epoch 400/500, Generator Loss: 0.0420, Critic Loss: -0.0149\n",
      "Epoch 401/500, Generator Loss: 0.1387, Critic Loss: 0.0005\n",
      "Epoch 402/500, Generator Loss: 0.1028, Critic Loss: -0.0462\n",
      "Epoch 403/500, Generator Loss: 0.0592, Critic Loss: -0.0113\n",
      "Epoch 404/500, Generator Loss: 0.0298, Critic Loss: -0.0073\n",
      "Epoch 405/500, Generator Loss: 0.0586, Critic Loss: -0.0214\n",
      "Epoch 406/500, Generator Loss: 0.0230, Critic Loss: -0.0062\n",
      "Epoch 407/500, Generator Loss: -0.1742, Critic Loss: -0.0595\n",
      "Epoch 408/500, Generator Loss: 0.0063, Critic Loss: -0.0030\n",
      "Epoch 409/500, Generator Loss: 0.1105, Critic Loss: 0.0004\n",
      "Epoch 410/500, Generator Loss: 0.0920, Critic Loss: -0.0027\n",
      "Epoch 411/500, Generator Loss: 0.1252, Critic Loss: -0.0149\n",
      "Epoch 412/500, Generator Loss: 0.0587, Critic Loss: -0.0088\n",
      "Epoch 413/500, Generator Loss: 0.1096, Critic Loss: -0.0116\n",
      "Epoch 414/500, Generator Loss: 0.0909, Critic Loss: -0.0033\n",
      "Epoch 415/500, Generator Loss: 0.0980, Critic Loss: -0.0086\n",
      "Epoch 416/500, Generator Loss: 0.0836, Critic Loss: -0.0112\n",
      "Epoch 417/500, Generator Loss: 0.0193, Critic Loss: -0.0093\n",
      "Epoch 418/500, Generator Loss: 0.0899, Critic Loss: -0.0040\n",
      "Epoch 419/500, Generator Loss: -0.0096, Critic Loss: -0.0179\n",
      "Epoch 420/500, Generator Loss: -0.0248, Critic Loss: -0.0121\n",
      "Epoch 421/500, Generator Loss: -0.0443, Critic Loss: -0.0031\n",
      "Epoch 422/500, Generator Loss: -0.0716, Critic Loss: -0.0030\n",
      "Epoch 423/500, Generator Loss: 0.0377, Critic Loss: 0.0034\n",
      "Epoch 424/500, Generator Loss: -0.0263, Critic Loss: -0.0089\n",
      "Epoch 425/500, Generator Loss: 0.0221, Critic Loss: -0.0035\n",
      "Epoch 426/500, Generator Loss: 0.0427, Critic Loss: -0.0026\n",
      "Epoch 427/500, Generator Loss: -0.0071, Critic Loss: -0.0013\n",
      "Epoch 428/500, Generator Loss: -0.0350, Critic Loss: 0.0006\n",
      "Epoch 429/500, Generator Loss: -0.0695, Critic Loss: -0.0109\n",
      "Epoch 430/500, Generator Loss: 0.1188, Critic Loss: 0.0114\n",
      "Epoch 431/500, Generator Loss: -0.0486, Critic Loss: -0.0116\n",
      "Epoch 432/500, Generator Loss: 0.0064, Critic Loss: -0.0366\n",
      "Epoch 433/500, Generator Loss: 0.1058, Critic Loss: 0.0043\n",
      "Epoch 434/500, Generator Loss: 0.0128, Critic Loss: -0.0157\n",
      "Epoch 435/500, Generator Loss: -0.1166, Critic Loss: -0.0199\n",
      "Epoch 436/500, Generator Loss: -0.1917, Critic Loss: -0.0115\n",
      "Epoch 437/500, Generator Loss: -0.1202, Critic Loss: -0.0052\n",
      "Epoch 438/500, Generator Loss: -0.0959, Critic Loss: -0.0085\n",
      "Epoch 439/500, Generator Loss: -0.1483, Critic Loss: -0.0036\n",
      "Epoch 440/500, Generator Loss: -0.1294, Critic Loss: -0.0066\n",
      "Epoch 441/500, Generator Loss: -0.1222, Critic Loss: -0.0170\n",
      "Epoch 442/500, Generator Loss: -0.1586, Critic Loss: -0.0050\n",
      "Epoch 443/500, Generator Loss: -0.1159, Critic Loss: -0.0097\n",
      "Epoch 444/500, Generator Loss: -0.2002, Critic Loss: -0.0088\n",
      "Epoch 445/500, Generator Loss: -0.0410, Critic Loss: 0.0512\n",
      "Epoch 446/500, Generator Loss: -0.1480, Critic Loss: -0.0068\n",
      "Epoch 447/500, Generator Loss: -0.0934, Critic Loss: -0.0066\n",
      "Epoch 448/500, Generator Loss: -0.1426, Critic Loss: -0.0141\n",
      "Epoch 449/500, Generator Loss: -0.1233, Critic Loss: 0.0035\n",
      "Epoch 450/500, Generator Loss: -0.1880, Critic Loss: -0.0022\n",
      "Epoch 451/500, Generator Loss: -0.1218, Critic Loss: -0.0143\n",
      "Epoch 452/500, Generator Loss: -0.1451, Critic Loss: -0.0166\n",
      "Epoch 453/500, Generator Loss: -0.1284, Critic Loss: -0.0169\n",
      "Epoch 454/500, Generator Loss: -0.1611, Critic Loss: -0.0046\n",
      "Epoch 455/500, Generator Loss: -0.1175, Critic Loss: -0.0055\n",
      "Epoch 456/500, Generator Loss: -0.1253, Critic Loss: -0.0100\n",
      "Epoch 457/500, Generator Loss: -0.1330, Critic Loss: -0.0031\n",
      "Epoch 458/500, Generator Loss: -0.1998, Critic Loss: 0.0007\n",
      "Epoch 459/500, Generator Loss: -0.0869, Critic Loss: -0.0181\n",
      "Epoch 460/500, Generator Loss: -0.1645, Critic Loss: -0.0094\n",
      "Epoch 461/500, Generator Loss: -0.0902, Critic Loss: -0.0087\n",
      "Epoch 462/500, Generator Loss: -0.1855, Critic Loss: -0.0059\n",
      "Epoch 463/500, Generator Loss: -0.1228, Critic Loss: -0.0153\n",
      "Epoch 464/500, Generator Loss: -0.1106, Critic Loss: -0.0042\n",
      "Epoch 465/500, Generator Loss: -0.1525, Critic Loss: -0.0129\n",
      "Epoch 466/500, Generator Loss: -0.1221, Critic Loss: -0.0133\n",
      "Epoch 467/500, Generator Loss: -0.2328, Critic Loss: -0.0022\n",
      "Epoch 468/500, Generator Loss: -0.0673, Critic Loss: -0.0098\n",
      "Epoch 469/500, Generator Loss: -0.1506, Critic Loss: -0.0143\n",
      "Epoch 470/500, Generator Loss: -0.1930, Critic Loss: -0.0079\n",
      "Epoch 471/500, Generator Loss: -0.1500, Critic Loss: -0.0093\n",
      "Epoch 472/500, Generator Loss: -0.0936, Critic Loss: -0.0037\n",
      "Epoch 473/500, Generator Loss: -0.0775, Critic Loss: -0.0082\n",
      "Epoch 474/500, Generator Loss: -0.2354, Critic Loss: -0.0100\n",
      "Epoch 475/500, Generator Loss: -0.1152, Critic Loss: -0.0013\n",
      "Epoch 476/500, Generator Loss: -0.1466, Critic Loss: -0.0134\n",
      "Epoch 477/500, Generator Loss: -0.0878, Critic Loss: -0.0011\n",
      "Epoch 478/500, Generator Loss: -0.1296, Critic Loss: -0.0086\n",
      "Epoch 479/500, Generator Loss: -0.1161, Critic Loss: -0.0004\n",
      "Epoch 480/500, Generator Loss: -0.1038, Critic Loss: -0.0128\n",
      "Epoch 481/500, Generator Loss: -0.1445, Critic Loss: -0.0057\n",
      "Epoch 482/500, Generator Loss: -0.1222, Critic Loss: -0.0019\n",
      "Epoch 483/500, Generator Loss: -0.0279, Critic Loss: -0.0102\n",
      "Epoch 484/500, Generator Loss: -0.0446, Critic Loss: -0.0145\n",
      "Epoch 485/500, Generator Loss: -0.0939, Critic Loss: -0.0162\n",
      "Epoch 486/500, Generator Loss: -0.0768, Critic Loss: -0.0077\n",
      "Epoch 487/500, Generator Loss: -0.0214, Critic Loss: -0.0098\n",
      "Epoch 488/500, Generator Loss: -0.0501, Critic Loss: -0.0015\n",
      "Epoch 489/500, Generator Loss: 0.0645, Critic Loss: 0.0103\n",
      "Epoch 490/500, Generator Loss: -0.0077, Critic Loss: -0.0089\n",
      "Epoch 491/500, Generator Loss: -0.3035, Critic Loss: -0.0426\n",
      "Epoch 492/500, Generator Loss: 0.1955, Critic Loss: -0.0019\n",
      "Epoch 493/500, Generator Loss: 0.3824, Critic Loss: -0.0044\n",
      "Epoch 494/500, Generator Loss: 0.2852, Critic Loss: -0.0120\n",
      "Epoch 495/500, Generator Loss: -0.1486, Critic Loss: -0.0267\n",
      "Epoch 496/500, Generator Loss: -0.0934, Critic Loss: 0.0281\n",
      "Epoch 497/500, Generator Loss: 0.0535, Critic Loss: -0.0565\n",
      "Epoch 498/500, Generator Loss: -0.0015, Critic Loss: -0.0323\n",
      "Epoch 499/500, Generator Loss: -0.1384, Critic Loss: -0.0119\n",
      "Epoch 500/500, Generator Loss: -0.5342, Critic Loss: 0.0404\n",
      "Training completed in 8.0 minutes\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load the real data\n",
    "root_path = '/srv/fs/my-notebooks'\n",
    "file_path = os.path.join(root_path, 'user_skill_feature_mapping.csv')\n",
    "real_data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the features used during GAN training\n",
    "aggregated_features = ['cutDirDeviation_mean', 'cutDirDeviation_std', \n",
    "                       'cutDistanceToCenter_mean', 'cutDistanceToCenter_std', \n",
    "                       'saberSpeed_mean', 'saberSpeed_std', \n",
    "                       'cutAngle_mean', 'cutAngle_std']\n",
    "X = real_data[aggregated_features].values.astype(np.float32)\n",
    "\n",
    "# WGAN-GP Parameters\n",
    "BUFFER_SIZE = X.shape[0]\n",
    "BATCH_SIZE = 64  # Reduced batch size\n",
    "LATENT_DIM = 128\n",
    "EPOCHS = 500\n",
    "CRITIC_ITERATIONS = 5\n",
    "GP_WEIGHT = 10.0\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Generator Model\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_dim=LATENT_DIM),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dense(X.shape[1], activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Critic Model (Discriminator equivalent in WGAN)\n",
    "def build_critic():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, input_shape=(X.shape[1],)),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1)  # No activation for WGAN\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Gradient Penalty Calculation with matched batch sizes\n",
    "def gradient_penalty(critic, real_data, fake_data):\n",
    "    # Ensure batch sizes are equal by resizing if necessary\n",
    "    batch_size = min(real_data.shape[0], fake_data.shape[0])\n",
    "    real_data = real_data[:batch_size]\n",
    "    fake_data = fake_data[:batch_size]\n",
    "    \n",
    "    real_data = tf.cast(real_data, tf.float32)\n",
    "    fake_data = tf.cast(fake_data, tf.float32)\n",
    "    \n",
    "    epsilon = tf.random.uniform([batch_size, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon * real_data + (1 - epsilon) * fake_data\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated)\n",
    "        pred = critic(interpolated)\n",
    "    grads = tape.gradient(pred, interpolated)\n",
    "    grads_l2 = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((grads_l2 - 1.0) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "# Loss functions\n",
    "def critic_loss(real_output, fake_output, gp):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) + GP_WEIGHT * gp\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=0.5, beta_2=0.9)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "# Custom training step for WGAN-GP\n",
    "@tf.function\n",
    "def distributed_train_step(real_data):\n",
    "    def train_step(real_data):\n",
    "        noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "\n",
    "        # Train Critic\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            with tf.GradientTape() as crit_tape:\n",
    "                fake_data = generator(noise)\n",
    "                real_output = critic(real_data)\n",
    "                fake_output = critic(fake_data)\n",
    "                gp = gradient_penalty(critic, real_data, fake_data)\n",
    "                crit_loss = critic_loss(real_output, fake_output, gp)\n",
    "            \n",
    "            critic_gradients = crit_tape.gradient(crit_loss, critic.trainable_variables)\n",
    "            critic_optimizer.apply_gradients(zip(critic_gradients, critic.trainable_variables))\n",
    "\n",
    "        # Train Generator\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_data = generator(noise)\n",
    "            fake_output = critic(fake_data)\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "\n",
    "        generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "\n",
    "        return gen_loss, crit_loss\n",
    "\n",
    "    # Run the step using the single GPU strategy\n",
    "    per_replica_gen_loss, per_replica_crit_loss = strategy.run(train_step, args=(real_data,))\n",
    "    \n",
    "    # Aggregate losses across replicas\n",
    "    total_gen_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_gen_loss, axis=None)\n",
    "    total_crit_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_crit_loss, axis=None)\n",
    "\n",
    "    return total_gen_loss, total_crit_loss\n",
    "\n",
    "# Training loop for WGAN-GP\n",
    "def train_wgan_gp(generator, critic, dataset, epochs):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for real_data in dataset:\n",
    "            gen_loss, crit_loss = distributed_train_step(real_data)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Generator Loss: {gen_loss:.4f}, Critic Loss: {crit_loss:.4f}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time // 60} minutes\")\n",
    "\n",
    "# Dataset preparation\n",
    "def prepare_dataset():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "# Main execution\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")  # Single GPU for stability\n",
    "with strategy.scope():\n",
    "    generator = build_generator()\n",
    "    critic = build_critic()\n",
    "\n",
    "    dataset = prepare_dataset()\n",
    "\n",
    "    # Train the WGAN-GP\n",
    "    train_wgan_gp(generator, critic, dataset, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fd5bdb-6c3b-4a42-b338-55607bc03371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cutDirDeviation_mean  cutDirDeviation_std  cutDistanceToCenter_mean  \\\n",
      "0             -0.001712             0.999435                 -0.006841   \n",
      "1             -0.003251             0.992640                 -0.005330   \n",
      "2             -0.002491             0.984297                 -0.004461   \n",
      "3             -0.001528             0.995437                 -0.006087   \n",
      "4             -0.000257             1.004976                 -0.009085   \n",
      "\n",
      "   cutDistanceToCenter_std  saberSpeed_mean  saberSpeed_std  cutAngle_mean  \\\n",
      "0                 1.017986         0.007647        1.015966       0.018947   \n",
      "1                 1.008172         0.009244        1.007786       0.017057   \n",
      "2                 1.000382         0.007055        1.001602       0.017351   \n",
      "3                 1.014217         0.008096        1.011679       0.019237   \n",
      "4                 1.025519         0.008893        1.019437       0.020453   \n",
      "\n",
      "   cutAngle_std  \n",
      "0      1.025492  \n",
      "1      1.017061  \n",
      "2      1.004769  \n",
      "3      1.024057  \n",
      "4      1.035314  \n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "def generate_synthetic_data(generator, num_samples):\n",
    "    noise = tf.random.normal([num_samples, LATENT_DIM])\n",
    "    synthetic_data = generator(noise)\n",
    "    return synthetic_data.numpy()\n",
    "\n",
    "# Example: Generate 1000 synthetic data points\n",
    "num_samples = 1000\n",
    "synthetic_data = generate_synthetic_data(generator, num_samples)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "synthetic_df = pd.DataFrame(synthetic_data, columns=aggregated_features)\n",
    "print(synthetic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f5c88c-80f1-4bcd-9031-d9b854c70e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Data Statistics:\n",
      "        cutDirDeviation_mean  cutDirDeviation_std  cutDistanceToCenter_mean  \\\n",
      "count          2.598000e+03          2598.000000              2.598000e+03   \n",
      "mean           1.424928e-06             1.000007              8.794410e-07   \n",
      "std            8.784777e-05             0.000131              4.585554e-05   \n",
      "min           -6.338356e-04             0.994173             -9.708187e-05   \n",
      "25%           -9.605894e-18             1.000001             -8.821337e-18   \n",
      "50%            1.725709e-18             1.000003              5.768350e-18   \n",
      "75%            1.523262e-17             1.000009              2.327524e-17   \n",
      "max            4.430973e-03             1.001131              2.335010e-03   \n",
      "\n",
      "       cutDistanceToCenter_std  saberSpeed_mean  saberSpeed_std  \\\n",
      "count              2598.000000     2.598000e+03     2598.000000   \n",
      "mean                  0.999143     1.009144e-07        0.999791   \n",
      "std                   0.027839     1.056026e-05        0.008837   \n",
      "min                   0.000000    -2.529140e-04        0.569852   \n",
      "25%                   1.000001    -3.589612e-17        1.000001   \n",
      "50%                   1.000003     4.215818e-18        1.000003   \n",
      "75%                   1.000009     5.612851e-17        1.000009   \n",
      "max                   1.001131     4.733666e-04        1.001131   \n",
      "\n",
      "       cutAngle_mean  cutAngle_std  \n",
      "count   2.598000e+03   2598.000000  \n",
      "mean    3.833808e-07      0.999143  \n",
      "std     1.746376e-05      0.027839  \n",
      "min    -3.307197e-05      0.000000  \n",
      "25%     6.800738e-18      1.000001  \n",
      "50%     3.643835e-17      1.000003  \n",
      "75%     7.024932e-17      1.000009  \n",
      "max     8.786748e-04      1.001131  \n",
      "\n",
      "Synthetic Data Statistics:\n",
      "        cutDirDeviation_mean  cutDirDeviation_std  cutDistanceToCenter_mean  \\\n",
      "count           1000.000000          1000.000000               1000.000000   \n",
      "mean              -0.001733             0.996610                 -0.006630   \n",
      "std                0.001197             0.005756                  0.002168   \n",
      "min               -0.006228             0.976982                 -0.019554   \n",
      "25%               -0.002470             0.992610                 -0.007923   \n",
      "50%               -0.001759             0.996582                 -0.006488   \n",
      "75%               -0.001047             1.000560                 -0.005216   \n",
      "max                0.005229             1.019530                  0.001943   \n",
      "\n",
      "       cutDistanceToCenter_std  saberSpeed_mean  saberSpeed_std  \\\n",
      "count              1000.000000      1000.000000     1000.000000   \n",
      "mean                  1.015108         0.007861        1.012552   \n",
      "std                   0.006666         0.001378        0.004976   \n",
      "min                   0.994400         0.002050        0.996427   \n",
      "25%                   1.010627         0.007071        1.009100   \n",
      "50%                   1.014927         0.007880        1.012440   \n",
      "75%                   1.019378         0.008720        1.015861   \n",
      "max                   1.039678         0.012788        1.029301   \n",
      "\n",
      "       cutAngle_mean  cutAngle_std  \n",
      "count    1000.000000   1000.000000  \n",
      "mean        0.019484      1.024201  \n",
      "std         0.001559      0.007619  \n",
      "min         0.008965      1.001058  \n",
      "25%         0.018691      1.018925  \n",
      "50%         0.019517      1.024173  \n",
      "75%         0.020368      1.029299  \n",
      "max         0.027481      1.049767  \n"
     ]
    }
   ],
   "source": [
    "# Real data statistics\n",
    "real_stats = real_data[aggregated_features].describe()\n",
    "\n",
    "# Synthetic data statistics\n",
    "synthetic_stats = synthetic_df.describe()\n",
    "\n",
    "print(\"Real Data Statistics:\\n\", real_stats)\n",
    "print(\"\\nSynthetic Data Statistics:\\n\", synthetic_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76083855-57c2-4a3a-a3b1-5b195845049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Test for cutDirDeviation_mean: Stat = 0.9342301770592764, P-value = 0.0\n",
      "KS Test for cutDirDeviation_std: Stat = 0.7228452655889146, P-value = 1.18e-321\n",
      "KS Test for cutDistanceToCenter_mean: Stat = 0.998, P-value = 0.0\n",
      "KS Test for cutDistanceToCenter_std: Stat = 0.9888452655889145, P-value = 0.0\n",
      "KS Test for saberSpeed_mean: Stat = 1.0, P-value = 0.0\n",
      "KS Test for saberSpeed_std: Stat = 0.9948452655889145, P-value = 0.0\n",
      "KS Test for cutAngle_mean: Stat = 1.0, P-value = 0.0\n",
      "KS Test for cutAngle_std: Stat = 0.9996150885296382, P-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for feature in aggregated_features:\n",
    "    real_values = real_data[feature].values\n",
    "    synthetic_values = synthetic_df[feature].values\n",
    "    \n",
    "    ks_stat, p_value = stats.ks_2samp(real_values, synthetic_values)\n",
    "    print(f\"KS Test for {feature}: Stat = {ks_stat}, P-value = {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c023ece4-d4b2-422c-9b2d-4df1874bba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic data to CSV\n",
    "synthetic_df.to_csv('/srv/fs/my-notebooks/synthetic_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038bd2d-3bab-4611-b447-353b095d8b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Privacy",
   "language": "python",
   "name": "tf-privacy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
